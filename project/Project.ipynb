{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :]  # we only take the first two features.\n",
    "Y = iris.target\n",
    "# print(X.T.shape)\n",
    "# print(Y.T.shape)\n",
    "dataset = np.concatenate([X.T, [Y.T]]).T\n",
    "# print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DecisionTreeClassifierCustom():\n",
    "    def __init__(self, max_depth=10, min_count=10, is_binary=False):\n",
    "        self.tree = None\n",
    "        self.max_depth = max_depth\n",
    "        self.min_count = min_count\n",
    "        self.train_x = None\n",
    "        self.train_y = None\n",
    "        self.is_binary = is_binary\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        self.train_x = [(x, i) for i, x in enumerate(X)]\n",
    "        self.train_y = y\n",
    "        self.n_features = X.shape[1]\n",
    "        root = self._get_branch(self.train_x, self.train_y)\n",
    "        self._branch(root, self.train_y, 1)\n",
    "        self.tree = root\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        return self.train(X, y)\n",
    "    \n",
    "    def score(self, X, Y):\n",
    "        predictions = self.predict(X)\n",
    "        correct = 0\n",
    "        for i in range(len(Y)):\n",
    "            if Y[i] == predictions[i]:\n",
    "                correct += 1\n",
    "        return (correct/float(len(Y)))\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        pred_y = np.empty(X_test.shape[0])\n",
    "        for i, obs in enumerate(X_test):\n",
    "            pred_y[i] = self._predict_helper(self.tree, obs)\n",
    "        return pred_y\n",
    "            \n",
    "    def _predict_helper(self, node, obs):\n",
    "        if obs[node['index']] <= node['value']:\n",
    "            if isinstance(node['left'], dict):\n",
    "                return self._predict_helper(node['left'], obs)\n",
    "            else:\n",
    "                return node['left']\n",
    "        else:\n",
    "            if isinstance(node['right'], dict):\n",
    "                return self._predict_helper(node['right'], obs)\n",
    "            else:\n",
    "                return node['right']\n",
    "    \n",
    "    def _get_branch(self, X, y):\n",
    "        classes = list(np.unique(y))\n",
    "#         print('classes', classes)\n",
    "        b_index, b_value, b_score, b_groups = np.inf, np.inf, np.inf, None\n",
    "        for index in range(self.n_features):\n",
    "            for row, idx in X:\n",
    "                groups = self._test_split(index, 0.5 if self.is_binary else row[index], X)\n",
    "                gini = self._get_gini(groups, classes, y)\n",
    "                if gini < b_score:\n",
    "#                     print(gini)\n",
    "                    b_index, b_value, b_score, b_groups = index, 0.5 if self.is_binary else row[index], gini, groups\n",
    "#                     print(b_index, b_value, b_score)\n",
    "        return {'index':b_index, 'value':b_value, 'groups':b_groups}\n",
    "    \n",
    "    def _test_split(self, index, value, X):\n",
    "        less = []\n",
    "        more = []\n",
    "        for row, idx in X:\n",
    "            if row[index] <= value:\n",
    "                less.append((row, idx))\n",
    "            else:\n",
    "                more.append((row, idx))\n",
    "        return less, more\n",
    "    \n",
    "    def _get_gini(self, groups, classes, y):\n",
    "        gini = 0.0\n",
    "        for cls in classes:\n",
    "            for group in groups:\n",
    "                size = len(group)\n",
    "                if size == 0:\n",
    "#                     gini += 0.025\n",
    "                    continue\n",
    "                proportion = [y[x[1]] for x in group].count(cls) / float(size)\n",
    "                gini += (proportion * (1.0 - proportion))\n",
    "        return gini\n",
    "    \n",
    "    def _branch(self, node, y, depth):\n",
    "        left, right = node['groups']\n",
    "        del(node['groups'])\n",
    "        # check for a no split\n",
    "        if not left or not right:\n",
    "            node['left'] = self._to_leaf(left + right, y)\n",
    "            node['right'] = self._to_leaf(left + right, y)\n",
    "            \n",
    "            return\n",
    "        # check for max depth\n",
    "        if depth >= self.max_depth:\n",
    "            node['left'], node['right'] = self._to_leaf(left, y), self._to_leaf(right, y)\n",
    "            return\n",
    "        # process left child\n",
    "        if len(left) <= self.min_count:\n",
    "            node['left'] = self._to_leaf(left, y)\n",
    "        else:\n",
    "            node['left'] = self._get_branch(left, y)\n",
    "            self._branch(node['left'], y, depth+1)\n",
    "        # process right child\n",
    "        if len(right) <= self.min_count:\n",
    "            node['right'] = self._to_leaf(right, y)\n",
    "        else:\n",
    "            node['right'] = self._get_branch(right, y)\n",
    "            self._branch(node['right'], y, depth+1)\n",
    "            \n",
    "    def _to_leaf(self, group, y):\n",
    "        outcomes = [y[x[1]] for x in group]\n",
    "        return max(set(outcomes), key=outcomes.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import math\n",
    "\n",
    "def separate_for_boosting(X, Y, preds):\n",
    "    correct = np.array([(x,y) for x, y, p in zip(X, Y, preds) if y == p])\n",
    "    incorrect = np.array([(x,y) for x, y, p in zip(X, Y, preds) if y != p])\n",
    "    correct, incorrect = correct.T, incorrect.T\n",
    "    return correct, incorrect\n",
    "        \n",
    "\n",
    "def train_test_split(*args, ratio=0.2):\n",
    "    assert len(args) > 0\n",
    "    split_index = int(round(len(args[0]) * (1-ratio)))\n",
    "    train = [arg[:split_index] if arg is not None else None for arg in args]\n",
    "    test = [arg[split_index:] if arg is not None else None for arg in args]\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def load_csv(filename):\n",
    "    # loads the csv by given filename\n",
    "    lines = list(csv.reader(open(filename, \"r\")))\n",
    "    headers = lines[0]\n",
    "    index = [line[0] for line in lines[1:]]\n",
    "    dataset = [line[1:] for line in lines[1:]]\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i] = [float(x) for x in dataset[i]]\n",
    "    return dataset\n",
    "\n",
    "def split_dataset(dataset, splitRatio):\n",
    "    # splits the dataset by the given ratio\n",
    "    trainSize = int(len(dataset) * splitRatio)\n",
    "    trainSet = []\n",
    "    copy = list(dataset)\n",
    "    while len(trainSet) < trainSize:\n",
    "        index = random.randrange(len(copy))\n",
    "        trainSet.append(copy.pop(index))\n",
    "    return [trainSet, copy]\n",
    "\n",
    "def separateByClass(dataset):\n",
    "    # takes the last col as Y and groups the dataframe by that col\n",
    "    separated = {}\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset[i]\n",
    "        if (vector[-1] not in separated):\n",
    "            separated[vector[-1]] = []\n",
    "        separated[vector[-1]].append(vector)\n",
    "    return separated\n",
    "\n",
    "def summarize(dataset):\n",
    "    \n",
    "    summaries = [(np.mean(attribute), np.std(attribute)) for attribute in zip(*dataset)]\n",
    "    del summaries[-1]\n",
    "    return summaries\n",
    "\n",
    "def summarizeByClass(dataset):\n",
    "    # separates the dataset into each class and then stores the summary (mean, std) of each variable in the dict for every class in the dataset\n",
    "    separated = separateByClass(dataset)\n",
    "    summaries = {}\n",
    "    for classValue, instances in separated.items():\n",
    "        summaries[classValue] = summarize(instances)\n",
    "    return summaries\n",
    "\n",
    "def calculateProbability(x, mean, stdev):\n",
    "#     print(stdev)\n",
    "    if stdev == 0: stdev = 0.0000001\n",
    "    exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
    "    return (1 / (math.sqrt(2*math.pi) * stdev)) * exponent\n",
    "\n",
    "\n",
    "class GenericNB():\n",
    "    def __init__(self):\n",
    "        self.summaries = dict\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "#         print(X.shape, Y.shape)\n",
    "        self.summaries = summarizeByClass(dataset)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for i in range(len(X)):\n",
    "            result = self._predict(X[i])\n",
    "            predictions.append(result)\n",
    "        return predictions\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return np.array([list(self.calculateClassProbabilities(x).values()) for x in X])\n",
    "    \n",
    "    def score(self, X, Y):\n",
    "        predictions = self.predict(X)\n",
    "        correct = 0\n",
    "        for i in range(len(Y)):\n",
    "            if Y[i] == predictions[i]:\n",
    "                correct += 1\n",
    "        return (correct/float(len(Y)))\n",
    "    \n",
    "    def _predict(self, X):\n",
    "        probabilities = self.calculateClassProbabilities(X)\n",
    "        bestLabel, bestProb = None, -1\n",
    "        for classValue, probability in probabilities.items():\n",
    "            if bestLabel is None or probability > bestProb:\n",
    "                bestProb = probability\n",
    "                bestLabel = classValue\n",
    "        return bestLabel\n",
    "    \n",
    "    def calculateClassProbabilities(self, X):\n",
    "        probabilities = {}\n",
    "        for classValue, classSummaries in self.summaries.items():\n",
    "            probabilities[classValue] = 1\n",
    "            for i in range(len(classSummaries)):\n",
    "                mean, stdev = classSummaries[i]\n",
    "                x = X[i]\n",
    "                probabilities[classValue] *= calculateProbability(x, mean, stdev)\n",
    "        return probabilities\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# def computeError(pred, Y, weights):\n",
    "\n",
    "        \n",
    "# def boost(examples, weakLearner, rounds):\n",
    "#    distr = normalize([1.] * len(examples))\n",
    "#    hypotheses = [None] * rounds\n",
    "#    alpha = [0] * rounds\n",
    " \n",
    "#    for t in range(rounds):\n",
    "#       def drawExample():\n",
    "#          return examples[draw(distr)]\n",
    " \n",
    "#       hypotheses[t] = weakLearner(drawExample)\n",
    "#       hypothesisResults, error = computeError(hypotheses[t], examples, distr)\n",
    " \n",
    "#       alpha[t] = 0.5 * math.log((1 - error) / (.0001 + error))\n",
    "#       distr = normalize([d * math.exp(-alpha[t] * h)\n",
    "#                          for (d,h) in zip(distr, hypothesisResults)])\n",
    "#       print(\"Round %d, error %.3f\" % (t, error))\n",
    " \n",
    "#    def finalHypothesis(x):\n",
    "#       return sign(sum(a * h(x) for (a, h) in zip(alpha, hypotheses)))\n",
    " \n",
    "#    return finalHypothesis\n",
    "\n",
    "\n",
    "import itertools\n",
    "import sys, os, pickle\n",
    "\n",
    "def gen_folds(df,n_splits=10):\n",
    "    step = math.ceil(len(df) / n_splits)\n",
    "    size = len(df)\n",
    "    folds = []\n",
    "    random_index = np.floor(np.random.rand(len(df))*len(df)).astype(int)\n",
    "    for loc in range(0,size,step):\n",
    "        test_indexer = range(loc,size) if loc+step > size else range(loc,loc+step)\n",
    "        train_indexer = list(itertools.chain(range(0,loc),range(loc+step,size)))\n",
    "        folds.append([random_index[train_indexer],random_index[test_indexer]])\n",
    "    return folds\n",
    "\n",
    "def bootstrap_resample(X, n=None, n_datasets=100):\n",
    "    if n == None:\n",
    "        n = len(X)\n",
    "    \n",
    "    for i in range(n_datasets):\n",
    "        resample_i = np.floor(np.random.rand(n)*len(X)).astype(int)\n",
    "        X_resample = np.array(X[resample_i])\n",
    "        yield X_resample\n",
    "\n",
    "def get_ensemble_binary_classification(forest, X):\n",
    "    pred_y = np.zeros(shape=(len(X),))\n",
    "    for t in forest:\n",
    "        temp = t.predict(X)\n",
    "        pred_y += temp\n",
    "    pred_y = pred_y / len(forest)\n",
    "    return np.array([1 if x > 0.5 else 0 for x in pred_y ])\n",
    "\n",
    "def accuracy_score(Y, predictions):\n",
    "    correct = 0\n",
    "    for i in range(len(Y)):\n",
    "        if Y[i] == predictions[i]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(Y)))\n",
    "\n",
    "\n",
    "def map_continuous(f):\n",
    "    if f < -0.01: return 0\n",
    "    elif -0.01 < f < 0.01: return 1\n",
    "    else: return 2\n",
    "    \n",
    "def bin_continuous(arr):\n",
    "    return np.array([map_continuous(a) for a in arr])\n",
    "\n",
    "def main(dataset_name=\"iris\", model_name='both', verbose=2, folds=10, ensemble_size=9, bootstrap=True, save_name=None, load_name=None):\n",
    "    probas = []\n",
    "    iter_weights = []\n",
    "    global dataset\n",
    "    splitRatio = 0.67\n",
    "    dataset, X, Y = None, None, None\n",
    "    if dataset_name == 'finance':\n",
    "        filename = 'dataframe.csv'\n",
    "        dataset = np.array(load_csv(filename))\n",
    "        dataset = dataset[:200]\n",
    "        print(dataset.shape)\n",
    "        X = dataset.T[1:].T\n",
    "        Y = dataset.T[0].T\n",
    "        Y = bin_continuous(Y)\n",
    "    else:\n",
    "        iris = datasets.load_iris()\n",
    "        X = iris.data[:, :4]  # we only take the first 4 features.\n",
    "        Y = iris.target\n",
    "        dataset = np.concatenate([X.T, [Y.T]]).T\n",
    "        \n",
    "    \n",
    "    ensemble_2 = np.array([])\n",
    "    train_errs = []\n",
    "    test_errs = []\n",
    "    load_fail = True\n",
    "    \n",
    "    if load_name != None:\n",
    "        load_fail = False\n",
    "        file = os.getcwd()\n",
    "        file += '/saves/' + load_name + '.pickle'\n",
    "        try:\n",
    "            with open(file, 'rb') as load_file:\n",
    "                ensemble_2 = pickle.load(load_file)\n",
    "            if verbose > 0:\n",
    "                print('Ensemble loaded.')\n",
    "            if verbose > -1:\n",
    "                for train_idx, test_idx in gen_folds(X, n_splits=1):\n",
    "                    X_train, X_test = X[train_idx], X[test_idx]\n",
    "                    y_train, y_test = Y[train_idx], Y[test_idx]\n",
    "                    test_preds = get_ensemble_binary_classification(ensemble_2, X_test)\n",
    "                    test_acc = accuracy_score(y_test, test_preds)\n",
    "                    print(\"Cross-fold Ensemble Acc: \", test_acc)\n",
    "        except:\n",
    "            if verbose > -1:\n",
    "                print('Failed to load ensemble from %s' % file)\n",
    "            load_fail = True\n",
    "            \n",
    "    if load_fail:\n",
    "        print('Constructing new ensemble')\n",
    "        for fold_round, (train_idx, test_idx) in enumerate(gen_folds(X, n_splits=folds)):\n",
    "            if verbose > 0:\n",
    "                print('')\n",
    "                print(\"Running Fold %s\" % (fold_round+1))\n",
    "            ensemble = []\n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "            y_train, y_test = Y[train_idx], Y[test_idx]\n",
    "            \n",
    "            # trains model on non bootstrapped data first\n",
    "            if verbose > 1:\n",
    "                print('')\n",
    "            if model_name in ['decision tree', 'both']:\n",
    "                clf = DecisionTreeClassifierCustom()\n",
    "                clf.fit(X_train, y_train)\n",
    "                ensemble.append(clf)\n",
    "                if verbose > 1:\n",
    "                    print(\"Trained Classifer %s with score %1.4f\" % ('Decision Tree', clf.score(X_test, y_test)))\n",
    "\n",
    "            if model_name in ['naive bayes', 'both']:\n",
    "                nb = GenericNB()\n",
    "                nb.fit(X_test,y_train)\n",
    "                ensemble.append(nb)\n",
    "                if verbose > 1:\n",
    "                    print(\"Trained Classifer %s with score %1.4f\" % ('Naive Bayes', nb.score(X_test, y_test)))\n",
    "\n",
    "            if bootstrap == True:\n",
    "                if verbose > 0:\n",
    "                    print(\"Bootstrapping...\")\n",
    "                for boot_round, sample in enumerate(bootstrap_resample(np.asmatrix(X_train), n_datasets=ensemble_size)):\n",
    "                    if verbose > 1:\n",
    "                        print('')\n",
    "                    if model_name in ['decision tree', 'both']:\n",
    "                        clf = DecisionTreeClassifierCustom()\n",
    "                        clf.fit(sample, y_train)\n",
    "                        ensemble.append(clf)\n",
    "                        if verbose > 1:\n",
    "                            print(\"Trained Classifer %s with score %1.4f\" % ('Decision Tree', clf.score(X_test, y_test)))\n",
    "\n",
    "                    if model_name in ['naive bayes', 'both']:\n",
    "                        nb = GenericNB()\n",
    "                        nb.fit(sample,y_train)\n",
    "                        ensemble.append(nb)\n",
    "                        if verbose > 1:\n",
    "                            print(\"Trained Classifer %s with score %1.4f\" % ('Naive Bayes', nb.score(X_test, y_test)))\n",
    "                \n",
    "\n",
    "            train_preds = get_ensemble_binary_classification(ensemble, X_train)\n",
    "            test_preds = get_ensemble_binary_classification(ensemble, X_test)\n",
    "            train_acc = accuracy_score(y_train, train_preds)\n",
    "            test_acc = accuracy_score(y_test, test_preds)\n",
    "            if verbose > 0:\n",
    "                print(\"Fold Ensemble Scores train: %1.4f - test: %1.4f\" % (train_acc, test_acc))\n",
    "            train_errs.append(train_acc)\n",
    "            test_errs.append(test_acc)\n",
    "            ensemble_2 = np.concatenate([ensemble_2, ensemble])\n",
    "\n",
    "        if save_name != None:\n",
    "            file = os.getcwd()\n",
    "            file += '/saves/' + save_name + '.pickle'\n",
    "            with open(file, 'wb') as save_file:\n",
    "                save_file.write(pickle.dumps(ensemble_2))\n",
    "            if verbose > 0:\n",
    "                print('Ensemble saved.')\n",
    "        \n",
    "        if verbose > -1:\n",
    "            test_preds = get_ensemble_binary_classification(ensemble_2, X_test)\n",
    "            test_acc = accuracy_score(y_test, test_preds)\n",
    "            print(\"Cross-fold Ensemble Acc: \", test_acc)\n",
    "            print('Avg. Ensemble accuracy for train data:', np.mean(train_errs))\n",
    "            print('Avg. Ensemble accuracy for test data:', np.mean(test_errs))  \n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/www/Repositories/cse415/project\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 37)\n",
      "Constructing new ensemble\n",
      "\n",
      "Running Fold 1\n",
      "Bootstrapping...\n",
      "Fold Ensemble Scores train: 0.5667 - test: 0.6000\n",
      "\n",
      "Running Fold 2\n",
      "Bootstrapping...\n",
      "Fold Ensemble Scores train: 0.5778 - test: 0.5000\n",
      "\n",
      "Running Fold 3\n",
      "Bootstrapping...\n",
      "Fold Ensemble Scores train: 0.5667 - test: 0.6000\n",
      "\n",
      "Running Fold 4\n",
      "Bootstrapping...\n",
      "Fold Ensemble Scores train: 0.6111 - test: 0.2000\n",
      "\n",
      "Running Fold 5\n",
      "Bootstrapping...\n",
      "Fold Ensemble Scores train: 0.5611 - test: 0.6500\n",
      "\n",
      "Running Fold 6\n",
      "Bootstrapping...\n",
      "Fold Ensemble Scores train: 0.5556 - test: 0.7000\n",
      "\n",
      "Running Fold 7\n",
      "Bootstrapping...\n",
      "Fold Ensemble Scores train: 0.5667 - test: 0.6000\n",
      "\n",
      "Running Fold 8\n",
      "Bootstrapping...\n",
      "Fold Ensemble Scores train: 0.5611 - test: 0.6500\n",
      "\n",
      "Running Fold 9\n",
      "Bootstrapping...\n",
      "Fold Ensemble Scores train: 0.5722 - test: 0.5500\n",
      "\n",
      "Running Fold 10\n",
      "Bootstrapping...\n",
      "Fold Ensemble Scores train: 0.5611 - test: 0.6500\n",
      "Ensemble saved.\n",
      "Cross-fold Ensemble Acc:  0.65\n",
      "Avg. Ensemble accuracy for train data: 0.57\n",
      "Avg. Ensemble accuracy for test data: 0.57\n"
     ]
    }
   ],
   "source": [
    "main(dataset_name='finance', model_name='both', verbose=1, bootstrap=True, ensemble_size=9, folds=10, save_name='finacetest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which dataset would you like to use? ('finance' or 'iris'): finance\n",
      "Which model would you like to use? ('naive bayes', 'decision tree', 'both'): both\n",
      "Should we use Bootstrap Aggregating (Bagging)? (y/n): y\n",
      "What size ensemble would you like to use? (int): 10\n",
      "How many folds would you like to use? (int): 10\n",
      "Should we save the ensemble? (y/n): t\n",
      "Sorry I didn't recognize that answer. (y/n)\n",
      "Should we save the ensemble? (y/n): y\n",
      "Enter filename?: finance1\n",
      "Should we attempt to load an ensemble? (y/n): n\n",
      "How verbose should I be? (int, -1 (silent) - 2 (Everything)): 1\n",
      "\n",
      "Constructing new ensemble\n",
      "\n",
      "Running Fold 1\n",
      "Bootstrapping...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-192-b2417ca844cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;31m# print(program_kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mprogram_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-191-17a90c1e97c5>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(dataset_name, model_name, verbose, folds, ensemble_size, bootstrap, save_name, load_name)\u001b[0m\n\u001b[1;32m    271\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'decision tree'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'both'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                         \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifierCustom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m                         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m                         \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-117-eb3cb6dce549>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-117-eb3cb6dce549>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_branch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_branch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-117-eb3cb6dce549>\u001b[0m in \u001b[0;36m_branch\u001b[0;34m(self, node, y, depth)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_branch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_branch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;31m# process right child\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_count\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-117-eb3cb6dce549>\u001b[0m in \u001b[0;36m_branch\u001b[0;34m(self, node, y, depth)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'right'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_branch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_branch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'right'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_to_leaf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-117-eb3cb6dce549>\u001b[0m in \u001b[0;36m_branch\u001b[0;34m(self, node, y, depth)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_branch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_branch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;31m# process right child\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_count\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-117-eb3cb6dce549>\u001b[0m in \u001b[0;36m_branch\u001b[0;34m(self, node, y, depth)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'right'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_branch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_branch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'right'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_to_leaf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-117-eb3cb6dce549>\u001b[0m in \u001b[0;36m_branch\u001b[0;34m(self, node, y, depth)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'right'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_branch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_branch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'right'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_to_leaf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-117-eb3cb6dce549>\u001b[0m in \u001b[0;36m_branch\u001b[0;34m(self, node, y, depth)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'right'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_branch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_branch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'right'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_to_leaf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-117-eb3cb6dce549>\u001b[0m in \u001b[0;36m_branch\u001b[0;34m(self, node, y, depth)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'right'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_branch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_branch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'right'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_to_leaf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-117-eb3cb6dce549>\u001b[0m in \u001b[0;36m_branch\u001b[0;34m(self, node, y, depth)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_leaf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_branch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_branch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;31m# process right child\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-117-eb3cb6dce549>\u001b[0m in \u001b[0;36m_get_branch\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_binary\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                 \u001b[0mgini\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_gini\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgini\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mb_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m#                     print(gini)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-117-eb3cb6dce549>\u001b[0m in \u001b[0;36m_get_gini\u001b[0;34m(self, groups, classes, y)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;31m#                     gini += 0.025\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0mproportion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m                 \u001b[0mgini\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mproportion\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mproportion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgini\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-117-eb3cb6dce549>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;31m#                     gini += 0.025\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0mproportion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m                 \u001b[0mgini\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mproportion\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mproportion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgini\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "program_kwargs = dict(\n",
    "    dataset_name = None,\n",
    "    model_name = None,\n",
    "    ensemble_size = None,\n",
    "    folds = None,\n",
    "    bootstrap = None,\n",
    "    save_name = None,\n",
    "    load_name = None,\n",
    "    verbose = None\n",
    ")\n",
    "valid_datasets = ['iris', 'finance']\n",
    "while program_kwargs['dataset_name'] not in valid_datasets:\n",
    "    program_kwargs['dataset_name'] = str(input(\"Which dataset would you like to use? ('finance' or 'iris'): \")).lower()\n",
    "    if program_kwargs['dataset_name'] not in valid_datasets:\n",
    "        print(\"Sorry I didn't recognize that dataset.\")\n",
    "        \n",
    "valid_models = ['naive bayes', 'decision tree', 'both']\n",
    "while program_kwargs['model_name'] not in valid_models:\n",
    "    program_kwargs['model_name'] = str(input(\"Which model would you like to use? ('naive bayes', 'decision tree', 'both'): \")).lower()\n",
    "    if program_kwargs['model_name'] not in valid_models:\n",
    "        print(\"Sorry I didn't recognize that model.\")\n",
    "        \n",
    "       \n",
    "valid_bag_opts = ['y', 'n']\n",
    "while program_kwargs['bootstrap'] not in valid_bag_opts:\n",
    "    program_kwargs['bootstrap'] = str(input(\"Should we use Bootstrap Aggregating (Bagging)? (y/n): \")).lower()\n",
    "    if program_kwargs['bootstrap'] not in valid_bag_opts:\n",
    "        print(\"Sorry I didn't recognize that answer. (y/n)\")\n",
    "    else:\n",
    "        program_kwargs['bootstrap'] = True if program_kwargs['bootstrap'] == 'y' else False\n",
    "        break\n",
    "        \n",
    "if program_kwargs['bootstrap']:\n",
    "    while type(program_kwargs['ensemble_size']) != type(1):\n",
    "        try:\n",
    "            program_kwargs['ensemble_size'] = input(\"What size ensemble would you like to use? (int): \")\n",
    "            program_kwargs['ensemble_size'] = int(program_kwargs['ensemble_size'])\n",
    "        except:\n",
    "            print(\"Sorry I didn't recognize that number.\")\n",
    "            program_kwargs['ensemble_size'] = None\n",
    "            \n",
    "while type(program_kwargs['folds']) != type(1):\n",
    "        try:\n",
    "            program_kwargs['folds'] = input(\"How many folds would you like to use? (int): \")\n",
    "            program_kwargs['folds'] = int(program_kwargs['folds'])\n",
    "        except:\n",
    "            print(\"Sorry I didn't recognize that number.\")\n",
    "            program_kwargs['folds'] = None\n",
    "            \n",
    "save_opt, load_opt = None, None\n",
    "valid_opts = ['y', 'n']\n",
    "while save_opt not in valid_opts:\n",
    "    save_opt = str(input(\"Should we save the ensemble? (y/n): \")).lower()\n",
    "    if save_opt not in valid_opts:\n",
    "        print(\"Sorry I didn't recognize that answer. (y/n)\")\n",
    "    else:\n",
    "        save_opt = True if save_opt == 'y' else False\n",
    "        break\n",
    "\n",
    "if save_opt:\n",
    "    program_kwargs['save_name'] = input(\"Enter filename?: \")\n",
    "    \n",
    "while load_opt not in valid_opts:\n",
    "    load_opt = str(input(\"Should we attempt to load an ensemble? (y/n): \")).lower()\n",
    "    if load_opt not in valid_opts:\n",
    "        print(\"Sorry I didn't recognize that answer. (y/n)\")\n",
    "    else:\n",
    "        load_opt = True if load_opt == 'y' else False\n",
    "        break\n",
    "\n",
    "if load_opt:\n",
    "    program_kwargs['load_name'] = input(\"Enter filename?: \")\n",
    "    \n",
    "       \n",
    "while type(program_kwargs['verbose']) != type(1):\n",
    "    try:\n",
    "        program_kwargs['verbose'] = input(\"How verbose should I be? (int, -1 (silent) - 2 (Everything)): \")\n",
    "        program_kwargs['verbose'] = int(program_kwargs['verbose'])\n",
    "    except:\n",
    "        print(\"Sorry I didn't recognize that number.\")\n",
    "        program_kwargs['verbose'] = None\n",
    "\n",
    "print()\n",
    "# print('Options')\n",
    "# print(program_kwargs)\n",
    "\n",
    "main(**program_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
